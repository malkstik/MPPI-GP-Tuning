{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argv[0]=--opengl2\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from run import *\n",
    "OBS_INIT = 4\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argv[0]=--opengl2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 0:   0%|          | 0/500 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     collected_data \u001b[39m=\u001b[39m collect_data(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/run.py:65\u001b[0m, in \u001b[0;36mcollect_data\u001b[0;34m(obsInit)\u001b[0m\n\u001b[1;32m     62\u001b[0m env\u001b[39m.\u001b[39mreset()\n\u001b[1;32m     63\u001b[0m controller \u001b[39m=\u001b[39m PushingController(env, pushing_multistep_residual_dynamics_model,\n\u001b[1;32m     64\u001b[0m                         obstacle_avoidance_pushing_cost_function, num_samples\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, horizon\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m collected_data \u001b[39m=\u001b[39m collect_data_GP(env, controller)\n\u001b[1;32m     66\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcollected_data_OBS_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(obsInit) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.npy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m np\u001b[39m.\u001b[39msave(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(filename), collected_data)   \n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/OptimizeHP.py:78\u001b[0m, in \u001b[0;36mcollect_data_GP\u001b[0;34m(env, controller, dataset_size)\u001b[0m\n\u001b[1;32m     76\u001b[0m controller\u001b[39m.\u001b[39mmppi\u001b[39m.\u001b[39my_weight \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mhyperparameters\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m3\u001b[39m]\n\u001b[1;32m     77\u001b[0m controller\u001b[39m.\u001b[39mmppi\u001b[39m.\u001b[39mtheta_weight \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mhyperparameters\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m4\u001b[39m]\n\u001b[0;32m---> 78\u001b[0m steps, goal_distance, goal_reached \u001b[39m=\u001b[39m execute(env, controller)\n\u001b[1;32m     79\u001b[0m \u001b[39m# Add cost to data\u001b[39;00m\n\u001b[1;32m     80\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mcost\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m execution_cost(steps, goal_distance, goal_reached)\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/OptimizeHP.py:35\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(env, controller, num_steps_max)\u001b[0m\n\u001b[1;32m     33\u001b[0m state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n\u001b[1;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_steps_max):\n\u001b[0;32m---> 35\u001b[0m     action \u001b[39m=\u001b[39m controller\u001b[39m.\u001b[39;49mcontrol(state)\n\u001b[1;32m     36\u001b[0m     state, reward, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m     37\u001b[0m     \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/learning_state_dynamics.py:654\u001b[0m, in \u001b[0;36mPushingController.control\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    652\u001b[0m state_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(state)\n\u001b[1;32m    653\u001b[0m \u001b[39m# ---\u001b[39;00m\n\u001b[0;32m--> 654\u001b[0m action_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmppi\u001b[39m.\u001b[39;49mcommand(state_tensor)\n\u001b[1;32m    655\u001b[0m \u001b[39m# --- Your code here\u001b[39;00m\n\u001b[1;32m    656\u001b[0m action \u001b[39m=\u001b[39m action_tensor\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/mppi.py:228\u001b[0m, in \u001b[0;36mMPPI.command\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mroll(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, dims\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    226\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mu_init\n\u001b[0;32m--> 228\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_command(state)\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/mppi.py:234\u001b[0m, in \u001b[0;36mMPPI._command\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    232\u001b[0m     state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(state)\n\u001b[1;32m    233\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39md)\n\u001b[0;32m--> 234\u001b[0m cost_total \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_total_cost_batch()\n\u001b[1;32m    235\u001b[0m beta \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmin(cost_total)\n\u001b[1;32m    236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcost_total_non_zero \u001b[39m=\u001b[39m _ensure_non_zero(cost_total, beta, \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlambda_)\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/mppi.py:321\u001b[0m, in \u001b[0;36mMPPI._compute_total_cost_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[39m# NOTE: The original paper does self.lambda_ * torch.abs(self.noise) @ self.noise_sigma_inv, but this biases\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[39m# the actions with low noise if all states have the same cost. With abs(noise) we prefer actions close to the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[39m# nomial trajectory.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     action_cost \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlambda_ \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnoise \u001b[39m@\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnoise_sigma_inv  \u001b[39m# Like original paper\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcost_total, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_rollout_costs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mperturbed_action)\n\u001b[1;32m    322\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactions \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mu_scale\n\u001b[1;32m    324\u001b[0m \u001b[39m# action perturbation cost\u001b[39;00m\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/mppi.py:275\u001b[0m, in \u001b[0;36mMPPI._compute_rollout_costs\u001b[0;34m(self, perturbed_actions)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(T):\n\u001b[1;32m    274\u001b[0m     u \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mu_scale \u001b[39m*\u001b[39m perturbed_actions[:, t]\u001b[39m.\u001b[39mrepeat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mM, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 275\u001b[0m     state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dynamics(state, u, t)\n\u001b[1;32m    277\u001b[0m     \u001b[39m#COST FUNCTION\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     c \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_running_cost(state, u, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_center, Q)\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/mppi.py:65\u001b[0m, in \u001b[0;36mhandle_batch_input.<locals>._handle_batch_input.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m# reduce all batch dimensions down to the first one\u001b[39;00m\n\u001b[1;32m     64\u001b[0m args \u001b[39m=\u001b[39m [v\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m*\u001b[39mv\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m(n \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):]) \u001b[39mif\u001b[39;00m (is_tensor_like(v) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(v\u001b[39m.\u001b[39mshape) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m) \u001b[39melse\u001b[39;00m v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m args]\n\u001b[0;32m---> 65\u001b[0m ret \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39m# restore original batch dimensions; keep variable dimension (nx)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(ret) \u001b[39mis\u001b[39;00m \u001b[39mtuple\u001b[39m:\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/mppi.py:213\u001b[0m, in \u001b[0;36mMPPI._dynamics\u001b[0;34m(self, state, u, t)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39m@handle_batch_input\u001b[39m(n\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_dynamics\u001b[39m(\u001b[39mself\u001b[39m, state, u, t):\n\u001b[0;32m--> 213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mF(state, u, t) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_dependency \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mF(state, u)\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/learning_state_dynamics.py:636\u001b[0m, in \u001b[0;36mPushingController._compute_dynamics\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[39m# --- Your code here\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 636\u001b[0m     next_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(state,action)\n\u001b[1;32m    637\u001b[0m \u001b[39m# ---\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39mreturn\u001b[39;00m next_state\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/learning_state_dynamics.py:381\u001b[0m, in \u001b[0;36mResidualDynamicsModel.forward\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39m# --- Your code here\u001b[39;00m\n\u001b[1;32m    380\u001b[0m state_action \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((state,action), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 381\u001b[0m delta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlin1(state_action)\n\u001b[1;32m    382\u001b[0m delta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact1(delta)\n\u001b[1;32m    383\u001b[0m delta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin2(delta)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    collected_data = collect_data(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = load_data(OBS_INIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gp(train_x, train_y, OBS_INIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimum_hp, optimum_cost = run_TS(train_x, train_y, OBS_INIT)\n",
    "print('Optimal HP: ', optimum_hp)\n",
    "print('Optimal Cost: ', optimum_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4_w,8)-aCMA-ES (mu_w=2.6,w_1=52%) in dimension 5 (seed=536188, Thu Apr 13 22:00:04 2023)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1      8 1.184725280587977e+01 1.0e+00 1.03e+00  1e+00  1e+00 2:57.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run_CMA(OBS_INIT)\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/run.py:143\u001b[0m, in \u001b[0;36mrun_CMA\u001b[0;34m(obsInit)\u001b[0m\n\u001b[1;32m    141\u001b[0m opts \u001b[39m=\u001b[39m cma\u001b[39m.\u001b[39mCMAOptions()\n\u001b[1;32m    142\u001b[0m opts\u001b[39m.\u001b[39mset(\u001b[39m\"\u001b[39m\u001b[39mbounds\u001b[39m\u001b[39m\"\u001b[39m, [[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m], [\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m]])\n\u001b[0;32m--> 143\u001b[0m res \u001b[39m=\u001b[39m cma\u001b[39m.\u001b[39;49mfmin(CMA_evaluate, [\u001b[39m0.5\u001b[39;49m, \u001b[39m0.01\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m0.1\u001b[39;49m], \u001b[39m1\u001b[39;49m, opts)\n\u001b[1;32m    144\u001b[0m es \u001b[39m=\u001b[39m cma\u001b[39m.\u001b[39mCMAEvolutionStrategy([\u001b[39m0.5\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0.1\u001b[39m], \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39moptimize(CMA_evaluate)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/cma/evolution_strategy.py:4818\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(objective_function, x0, sigma0, options, args, gradf, restarts, restart_from_best, incpopsize, eval_initial_x, parallel_objective, noise_handler, noise_change_sigma_exponent, noise_kappa_exponent, bipop, callback)\u001b[0m\n\u001b[1;32m   4815\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m   4816\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m es\u001b[39m.\u001b[39mstop():  \u001b[39m# iteration loop\u001b[39;00m\n\u001b[1;32m   4817\u001b[0m         \u001b[39m# X, fit = eval_in_parallel(lambda: es.ask(1)[0], es.popsize, args, repetitions=noisehandler.evaluations-1)\u001b[39;00m\n\u001b[0;32m-> 4818\u001b[0m         X, fit \u001b[39m=\u001b[39m es\u001b[39m.\u001b[39;49mask_and_eval(parallel_objective \u001b[39mor\u001b[39;49;00m objective_function,\n\u001b[1;32m   4819\u001b[0m                                  args, gradf\u001b[39m=\u001b[39;49mgradf,\n\u001b[1;32m   4820\u001b[0m                                  evaluations\u001b[39m=\u001b[39;49mnoisehandler\u001b[39m.\u001b[39;49mevaluations,\n\u001b[1;32m   4821\u001b[0m                                  aggregation\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mmedian,\n\u001b[1;32m   4822\u001b[0m                                  parallel_mode\u001b[39m=\u001b[39;49mparallel_objective)  \u001b[39m# treats NaN with resampling if not parallel_mode\u001b[39;00m\n\u001b[1;32m   4823\u001b[0m         \u001b[39m# TODO: check args and in case use args=(noisehandler.evaluations, )\u001b[39;00m\n\u001b[1;32m   4825\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m11\u001b[39m \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m opts[\u001b[39m'\u001b[39m\u001b[39mvv\u001b[39m\u001b[39m'\u001b[39m]:  \u001b[39m# inject a solution\u001b[39;00m\n\u001b[1;32m   4826\u001b[0m             \u001b[39m# use option check_point = [0]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/cma/evolution_strategy.py:2528\u001b[0m, in \u001b[0;36mCMAEvolutionStrategy.ask_and_eval\u001b[0;34m(self, func, args, gradf, number, xmean, sigma_fac, evaluations, aggregation, kappa, parallel_mode)\u001b[0m\n\u001b[1;32m   2524\u001b[0m     length_normalizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmahalanobis_norm(x \u001b[39m-\u001b[39m xmean)  \u001b[39m# self.const.chiN < N**0.5, the constant here is irrelevant (absorbed by kappa)\u001b[39;00m\n\u001b[1;32m   2525\u001b[0m     \u001b[39m# print(self.N**0.5 / self.mahalanobis_norm(x - xmean))\u001b[39;00m\n\u001b[1;32m   2526\u001b[0m     \u001b[39m# self.more_to_write += [length_normalizer * 1e-3, length_normalizer * self.mahalanobis_norm(x - xmean) * 1e2]\u001b[39;00m\n\u001b[0;32m-> 2528\u001b[0m f \u001b[39m=\u001b[39m func(x, \u001b[39m*\u001b[39;49margs) \u001b[39mif\u001b[39;00m kappa \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \\\n\u001b[1;32m   2529\u001b[0m     func(xmean \u001b[39m+\u001b[39m kappa \u001b[39m*\u001b[39m length_normalizer \u001b[39m*\u001b[39m (x \u001b[39m-\u001b[39m xmean),\n\u001b[1;32m   2530\u001b[0m          \u001b[39m*\u001b[39margs)\n\u001b[1;32m   2531\u001b[0m \u001b[39mif\u001b[39;00m is_feasible(x, f) \u001b[39mand\u001b[39;00m evaluations \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2532\u001b[0m     f \u001b[39m=\u001b[39m aggregation([f] \u001b[39m+\u001b[39m [(func(x, \u001b[39m*\u001b[39margs) \u001b[39mif\u001b[39;00m kappa \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m\n\u001b[1;32m   2533\u001b[0m                             func(xmean \u001b[39m+\u001b[39m kappa \u001b[39m*\u001b[39m length_normalizer \u001b[39m*\u001b[39m (x \u001b[39m-\u001b[39m xmean), \u001b[39m*\u001b[39margs))\n\u001b[1;32m   2534\u001b[0m                            \u001b[39mfor\u001b[39;00m _i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mint\u001b[39m(evaluations \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m))])\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/run.py:132\u001b[0m, in \u001b[0;36mCMA_evaluate\u001b[0;34m(hyperparameters)\u001b[0m\n\u001b[1;32m    129\u001b[0m CMA_CONTROLLER\u001b[39m.\u001b[39mmppi\u001b[39m.\u001b[39mtheta_weight \u001b[39m=\u001b[39m hyperparameters[\u001b[39m4\u001b[39m]\n\u001b[1;32m    131\u001b[0m \u001b[39m#Simulate\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m i, goal_distance, goal_reached \u001b[39m=\u001b[39m execute(CMA_ENV, CMA_CONTROLLER)\n\u001b[1;32m    134\u001b[0m \u001b[39m#Retrieve cost\u001b[39;00m\n\u001b[1;32m    135\u001b[0m cost \u001b[39m=\u001b[39m execution_cost(i, goal_distance, goal_reached)\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/OptimizeHP.py:36\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(env, controller, num_steps_max)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_steps_max):\n\u001b[1;32m     35\u001b[0m     action \u001b[39m=\u001b[39m controller\u001b[39m.\u001b[39mcontrol(state)\n\u001b[0;32m---> 36\u001b[0m     state, reward, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     37\u001b[0m     \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m     38\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/panda_pushing_env.py:232\u001b[0m, in \u001b[0;36mPandaPushingEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    230\u001b[0m push_length \u001b[39m=\u001b[39m push_length_fraction \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_length\n\u001b[1;32m    231\u001b[0m \u001b[39m# Perform the action\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpush(push_location, push_angle, push_length\u001b[39m=\u001b[39;49mpush_length)\n\u001b[1;32m    233\u001b[0m state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_state()\n\u001b[1;32m    234\u001b[0m reward \u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/panda_pushing_env.py:294\u001b[0m, in \u001b[0;36mPandaPushingEnv.push\u001b[0;34m(self, push_location, push_angle, push_length)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39m# set theta\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlower_down()\n\u001b[0;32m--> 294\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplanar_push(theta, push_length\u001b[39m=\u001b[39;49mstart_gap\u001b[39m-\u001b[39;49m\u001b[39m0.015\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m.5\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock_size, step_size\u001b[39m=\u001b[39;49m\u001b[39m0.005\u001b[39;49m) \u001b[39m# push until barely touch the block\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_render_on \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplanar_push(push_angle \u001b[39m+\u001b[39m theta, push_length\u001b[39m=\u001b[39mpush_length, step_size\u001b[39m=\u001b[39m\u001b[39m0.005\u001b[39m)\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/panda_pushing_env.py:273\u001b[0m, in \u001b[0;36mPandaPushingEnv.planar_push\u001b[0;34m(self, push_angle, push_length, step_size)\u001b[0m\n\u001b[1;32m    271\u001b[0m current_pos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_end_effector_pos()\n\u001b[1;32m    272\u001b[0m target_pos \u001b[39m=\u001b[39m current_pos \u001b[39m+\u001b[39m push_length \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39mcos(push_angle), np\u001b[39m.\u001b[39msin(push_angle), \u001b[39m0\u001b[39m])\n\u001b[0;32m--> 273\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_move_ee_trajectory(target_pos, step_size\u001b[39m=\u001b[39;49mstep_size)\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/panda_pushing_env.py:309\u001b[0m, in \u001b[0;36mPandaPushingEnv._move_ee_trajectory\u001b[0;34m(self, target_ee_pos, step_size)\u001b[0m\n\u001b[1;32m    307\u001b[0m     target_ee_pos_i \u001b[39m=\u001b[39m start_ee_pos \u001b[39m+\u001b[39m step_size \u001b[39m*\u001b[39m step_i \u001b[39m*\u001b[39m goal_dir\n\u001b[1;32m    308\u001b[0m     render_step_i \u001b[39m=\u001b[39m step_i \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_every_n_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 309\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_move_robot_ee(target_ee_pos_i, render\u001b[39m=\u001b[39;49mrender_step_i)\n\u001b[1;32m    310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_move_robot_ee(target_ee_pos, render\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/gps-for-bayesian-optimization/panda_pushing_env.py:317\u001b[0m, in \u001b[0;36mPandaPushingEnv._move_robot_ee\u001b[0;34m(self, target_ee_pos, render)\u001b[0m\n\u001b[1;32m    315\u001b[0m repeat_counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    316\u001b[0m \u001b[39mwhile\u001b[39;00m distance \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mik_precision_treshold \u001b[39mand\u001b[39;00m repeat_counter \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_ik_repeat:\n\u001b[0;32m--> 317\u001b[0m     computed_ik_joint_pos \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mcalculateInverseKinematics(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpandaUid, \u001b[39m11\u001b[39;49m, target_ee_pos,\n\u001b[1;32m    318\u001b[0m                                                          \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_orientation)\n\u001b[1;32m    319\u001b[0m     \u001b[39m# Set the joints\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     p\u001b[39m.\u001b[39msetJointMotorControlArray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpandaUid, \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m7\u001b[39m)), p\u001b[39m.\u001b[39mPOSITION_CONTROL,\n\u001b[1;32m    321\u001b[0m                                 \u001b[39mlist\u001b[39m(computed_ik_joint_pos[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]), forces\u001b[39m=\u001b[39m[\u001b[39m500.0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m7\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_CMA(OBS_INIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimized 1\n",
    "hyperparameters = [5.38209705132172, 0.000818226196113964, 5.69249384639353, 3.435367933700074, 6.2953055533397855]\n",
    "\n",
    "evalHP(hyperparameters, 100, OBS_INIT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimized 1\n",
    "hyperparameters = [0.5, 0.01, 1, 1, 0.1]\n",
    "\n",
    "evalHP(hyperparameters, 100, OBS_INIT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
